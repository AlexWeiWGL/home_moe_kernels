#!/usr/bin/env python3
"""
HoMEä¼˜åŒ–æ¶æ„ä½¿ç”¨ç¤ºä¾‹å’Œæµ‹è¯•å¥—ä»¶

è¿™ä¸ªæ–‡ä»¶åŒ…å«äº†HoME (Hierarchical Mixture of Experts) ä¼˜åŒ–æ¶æ„çš„å®Œæ•´æµ‹è¯•å¥—ä»¶ï¼Œ
åŒ…æ‹¬ä»¥ä¸‹CUDAç®—å­çš„è¯¦ç»†æµ‹è¯•ï¼š

1. home_expert_forward - ä¸“å®¶ç½‘ç»œå‰å‘ä¼ æ’­
2. lora_gate_forward - LoRAé—¨æ§å‰å‘ä¼ æ’­  
3. gate_weights_forward - é—¨æ§æƒé‡å‰å‘ä¼ æ’­
4. expert_weighted_sum_forward - ä¸“å®¶åŠ æƒæ±‚å’Œ
5. fused_batch_norm_silu_forward - èåˆBatchNorm+SiLUç®—å­

ä½¿ç”¨æ–¹æ³•:
    python test_home_moe.py                    # è¿è¡Œæ‰€æœ‰æµ‹è¯•
    python test_home_moe.py --test kernels     # åªæµ‹è¯•CUDA kernels
    python test_home_moe.py --test performance # åªè¿è¡Œæ€§èƒ½æµ‹è¯•
    python test_home_moe.py --test accuracy    # åªè¿è¡Œç²¾åº¦éªŒè¯
    python test_home_moe.py --test basic       # åªè¿è¡ŒåŸºæœ¬ç¤ºä¾‹
    python test_home_moe.py --quick            # å¿«é€Ÿæµ‹è¯•æ¨¡å¼

æ¯ä¸ªç®—å­æµ‹è¯•åŒ…æ‹¬ï¼š
- åŠŸèƒ½æ­£ç¡®æ€§éªŒè¯
- è¾“å‡ºå½¢çŠ¶éªŒè¯
- æ•°å€¼ç²¾åº¦éªŒè¯ï¼ˆä¸PyTorchå®ç°å¯¹æ¯”ï¼‰
- æ€§èƒ½åŸºå‡†æµ‹è¯•
- å¤šç§æµ‹è¯•ç”¨ä¾‹è¦†ç›–
"""

import torch
import torch.nn as nn
import time
import sys
import os

# æ·»åŠ å½“å‰ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

# å°è¯•å¯¼å…¥CUDA kernelæ¨¡å—
try:
    import home_kernels
    CUDA_KERNELS_AVAILABLE = True
    print("âœ“ CUDA kernelsæ¨¡å—å¯¼å…¥æˆåŠŸ")
except ImportError as e:
    print(f"âš ï¸  CUDA kernelsæ¨¡å—å¯¼å…¥å¤±è´¥: {e}")
    print("å°†ä½¿ç”¨PyTorchåŸç”Ÿå®ç°ä½œä¸ºåå¤‡")
    CUDA_KERNELS_AVAILABLE = False
    home_kernels = None

def create_sample_data(batch_size=4096, device='cuda'):
    """åˆ›å»ºç¤ºä¾‹æ•°æ®"""
    # 6ä¸ªä»»åŠ¡çš„è¾“å…¥æ•°æ®
    input_states = [
        torch.randn(batch_size, 700, device=device) for _ in range(6)
    ]
    
    # é—¨æ§çŠ¶æ€
    l_gate_states = torch.randn(batch_size, 700, device=device)
    g_gate_states = torch.randn(batch_size, 700, device=device)
    l_gate_states_task = torch.randn(batch_size, 700, device=device)
    
    return input_states, l_gate_states, g_gate_states, l_gate_states_task

def print_gpu_memory():
    """æ‰“å°GPUå†…å­˜ä½¿ç”¨æƒ…å†µ"""
    if torch.cuda.is_available():
        allocated = torch.cuda.memory_allocated() / 1024**3
        reserved = torch.cuda.memory_reserved() / 1024**3
        print(f"GPUå†…å­˜ - å·²åˆ†é…: {allocated:.2f} GB, å·²ç¼“å­˜: {reserved:.2f} GB")
        return allocated, reserved
    return 0, 0

def clear_gpu_memory():
    """æ¸…ç†GPUå†…å­˜"""
    if torch.cuda.is_available():
        torch.cuda.empty_cache()
        print("GPUå†…å­˜å·²æ¸…ç†")

def test_home_expert_forward():
    """æµ‹è¯•home_expert_forwardç®—å­"""
    print("\n" + "=" * 60)
    print("æµ‹è¯• home_expert_forward ç®—å­")
    print("=" * 60)
    
    if not CUDA_KERNELS_AVAILABLE:
        print("âš ï¸  CUDA kernelsä¸å¯ç”¨ï¼Œè·³è¿‡æµ‹è¯•")
        return
    
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    
    # æµ‹è¯•å‚æ•°
    test_cases = [
        {"batch_size": 32, "input_dim": 256, "hidden_dim": 256, "num_experts": 5},
        {"batch_size": 64, "input_dim": 512, "hidden_dim": 512, "num_experts": 8},
        {"batch_size": 128, "input_dim": 128, "hidden_dim": 128, "num_experts": 3},
        {"batch_size": 4096, "input_dim": 700, "hidden_dim": 256, "num_experts": 5},  # é«˜ååé‡æµ‹è¯•ç”¨ä¾‹
    ]
    
    for i, case in enumerate(test_cases):
        print(f"\næµ‹è¯•ç”¨ä¾‹ {i+1}: {case}")
        print("-" * 40)
        
        batch_size = case["batch_size"]
        input_dim = case["input_dim"]
        hidden_dim = case["hidden_dim"]
        num_experts = case["num_experts"]
        
        # å¯¹äºé«˜ååé‡æµ‹è¯•ç”¨ä¾‹ï¼Œæ˜¾ç¤ºå†…å­˜ä½¿ç”¨æƒ…å†µ
        if batch_size >= 4096:
            print(f"  ğŸš€ é«˜ååé‡æµ‹è¯•ç”¨ä¾‹ - é¢„è®¡å†…å­˜ä½¿ç”¨: {batch_size * input_dim * 4 / 1024**2:.1f} MB (è¾“å…¥)")
            print_gpu_memory()
        
        # åˆ›å»ºæµ‹è¯•æ•°æ®
        torch.manual_seed(42)
        input_data = torch.randn(batch_size, input_dim, device=device)
        expert_weights = torch.randn(num_experts, input_dim, hidden_dim, device=device)
        expert_biases = torch.randn(num_experts, hidden_dim, device=device)
        expert_indices = torch.arange(num_experts, dtype=torch.int32, device=device)
        
        # æµ‹è¯•CUDA kernel
        try:
            with torch.no_grad():
                cuda_output = home_kernels.home_expert_forward(
                    input_data, expert_weights, expert_biases, expert_indices, num_experts, True
                )
            
            print(f"âœ“ CUDA kernelæ‰§è¡ŒæˆåŠŸ")
            print(f"  è¾“å‡ºå½¢çŠ¶: {cuda_output.shape}")
            print(f"  è¾“å‡ºæ•°æ®ç±»å‹: {cuda_output.dtype}")
            print(f"  è¾“å‡ºè®¾å¤‡: {cuda_output.device}")
            
            # éªŒè¯è¾“å‡ºå½¢çŠ¶
            expected_shape = (batch_size, num_experts, hidden_dim)
            if cuda_output.shape == expected_shape:
                print(f"âœ“ è¾“å‡ºå½¢çŠ¶æ­£ç¡®: {cuda_output.shape}")
            else:
                print(f"âœ— è¾“å‡ºå½¢çŠ¶é”™è¯¯: æœŸæœ› {expected_shape}, å®é™… {cuda_output.shape}")
            
            # æ€§èƒ½æµ‹è¯•
            times = []
            num_runs = 10
            
            # é¢„çƒ­
            for _ in range(3):
                with torch.no_grad():
                    _ = home_kernels.home_expert_forward(
                        input_data, expert_weights, expert_biases, expert_indices, num_experts, True
                    )
            
            # æµ‹è¯•
            for _ in range(num_runs):
                torch.cuda.synchronize()
                start_time = time.time()
                
                with torch.no_grad():
                    _ = home_kernels.home_expert_forward(
                        input_data, expert_weights, expert_biases, expert_indices, num_experts, True
                    )
                
                torch.cuda.synchronize()
                end_time = time.time()
                times.append((end_time - start_time) * 1000)
            
            avg_time = sum(times) / len(times)
            min_time = min(times)
            max_time = max(times)
            std_time = (sum((t - avg_time) ** 2 for t in times) / len(times)) ** 0.5
            
            print(f"  æ€§èƒ½ç»Ÿè®¡:")
            print(f"    å¹³å‡æ—¶é—´: {avg_time:.4f} ms")
            print(f"    æœ€å°æ—¶é—´: {min_time:.4f} ms")
            print(f"    æœ€å¤§æ—¶é—´: {max_time:.4f} ms")
            print(f"    æ ‡å‡†å·®: {std_time:.4f} ms")
            
            # å¯¹äºé«˜ååé‡æµ‹è¯•ç”¨ä¾‹ï¼Œè®¡ç®—ååé‡
            if batch_size >= 4096:
                throughput = batch_size / (avg_time / 1000)  # samples per second
                print(f"    ååé‡: {throughput:.0f} samples/sec")
                print_gpu_memory()
            
        except Exception as e:
            print(f"âœ— CUDA kernelæ‰§è¡Œå¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
    
    print("\nâœ“ home_expert_forward ç®—å­æµ‹è¯•å®Œæˆ!")


def test_lora_gate_forward():
    """æµ‹è¯•lora_gate_forwardç®—å­"""
    print("\n" + "=" * 60)
    print("æµ‹è¯• lora_gate_forward ç®—å­")
    print("=" * 60)
    
    if not CUDA_KERNELS_AVAILABLE:
        print("âš ï¸  CUDA kernelsä¸å¯ç”¨ï¼Œè·³è¿‡æµ‹è¯•")
        return
    
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    
    # æµ‹è¯•å‚æ•°
    test_cases = [
        {"batch_size": 32, "input_dim": 256, "rank": 16, "output_dim": 256},
        {"batch_size": 64, "input_dim": 512, "rank": 32, "output_dim": 512},
        {"batch_size": 128, "input_dim": 128, "rank": 8, "output_dim": 128},
        {"batch_size": 4096, "input_dim": 700, "rank": 16, "output_dim": 700},  # é«˜ååé‡æµ‹è¯•ç”¨ä¾‹
    ]
    
    for i, case in enumerate(test_cases):
        print(f"\næµ‹è¯•ç”¨ä¾‹ {i+1}: {case}")
        print("-" * 40)
        
        batch_size = case["batch_size"]
        input_dim = case["input_dim"]
        rank = case["rank"]
        output_dim = case["output_dim"]
        
        # å¯¹äºé«˜ååé‡æµ‹è¯•ç”¨ä¾‹ï¼Œæ˜¾ç¤ºå†…å­˜ä½¿ç”¨æƒ…å†µ
        if batch_size >= 4096:
            print(f"  ğŸš€ é«˜ååé‡æµ‹è¯•ç”¨ä¾‹ - é¢„è®¡å†…å­˜ä½¿ç”¨: {batch_size * input_dim * 4 / 1024**2:.1f} MB (è¾“å…¥)")
            print_gpu_memory()
        
        # åˆ›å»ºæµ‹è¯•æ•°æ®
        torch.manual_seed(42)
        input_data = torch.randn(batch_size, input_dim, device=device)
        A_matrix = torch.randn(input_dim, rank, device=device)
        B_matrix = torch.randn(rank, output_dim, device=device)
        
        # æµ‹è¯•CUDA kernel
        try:
            with torch.no_grad():
                cuda_output = home_kernels.lora_gate_forward(
                    input_data, A_matrix, B_matrix, True  # use_vectorized=True
                )
            
            print(f"âœ“ CUDA kernelæ‰§è¡ŒæˆåŠŸ")
            print(f"  è¾“å‡ºå½¢çŠ¶: {cuda_output.shape}")
            print(f"  è¾“å‡ºæ•°æ®ç±»å‹: {cuda_output.dtype}")
            print(f"  è¾“å‡ºè®¾å¤‡: {cuda_output.device}")
            
            # éªŒè¯è¾“å‡ºå½¢çŠ¶
            expected_shape = (batch_size, output_dim)
            if cuda_output.shape == expected_shape:
                print(f"âœ“ è¾“å‡ºå½¢çŠ¶æ­£ç¡®: {cuda_output.shape}")
            else:
                print(f"âœ— è¾“å‡ºå½¢çŠ¶é”™è¯¯: æœŸæœ› {expected_shape}, å®é™… {cuda_output.shape}")
            
            # ä¸PyTorchå®ç°å¯¹æ¯”éªŒè¯
            with torch.no_grad():
                pytorch_output = torch.matmul(torch.matmul(input_data, A_matrix), B_matrix)
            
            # è®¡ç®—æ•°å€¼å·®å¼‚
            diff = torch.abs(cuda_output - pytorch_output)
            max_diff = torch.max(diff).item()
            mean_diff = torch.mean(diff).item()
            
            print(f"  ä¸PyTorchå®ç°å¯¹æ¯”:")
            print(f"    æœ€å¤§å·®å¼‚: {max_diff:.6f}")
            print(f"    å¹³å‡å·®å¼‚: {mean_diff:.6f}")
            
            if max_diff < 1e-4:
                print(f"âœ“ æ•°å€¼ç²¾åº¦éªŒè¯é€šè¿‡")
            else:
                print(f"âš ï¸  æ•°å€¼ç²¾åº¦å¯èƒ½å­˜åœ¨å·®å¼‚")
            
            # æ€§èƒ½æµ‹è¯•
            times = []
            num_runs = 10
            
            # é¢„çƒ­
            for _ in range(3):
                with torch.no_grad():
                    _ = home_kernels.lora_gate_forward(input_data, A_matrix, B_matrix, True)
            
            # æµ‹è¯•
            for _ in range(num_runs):
                torch.cuda.synchronize()
                start_time = time.time()
                
                with torch.no_grad():
                    _ = home_kernels.lora_gate_forward(input_data, A_matrix, B_matrix, True)
                
                torch.cuda.synchronize()
                end_time = time.time()
                times.append((end_time - start_time) * 1000)
            
            avg_time = sum(times) / len(times)
            min_time = min(times)
            max_time = max(times)
            std_time = (sum((t - avg_time) ** 2 for t in times) / len(times)) ** 0.5
            
            print(f"  æ€§èƒ½ç»Ÿè®¡:")
            print(f"    å¹³å‡æ—¶é—´: {avg_time:.4f} ms")
            print(f"    æœ€å°æ—¶é—´: {min_time:.4f} ms")
            print(f"    æœ€å¤§æ—¶é—´: {max_time:.4f} ms")
            print(f"    æ ‡å‡†å·®: {std_time:.4f} ms")
            
            # å¯¹äºé«˜ååé‡æµ‹è¯•ç”¨ä¾‹ï¼Œè®¡ç®—ååé‡
            if batch_size >= 4096:
                throughput = batch_size / (avg_time / 1000)  # samples per second
                print(f"    ååé‡: {throughput:.0f} samples/sec")
                print_gpu_memory()
            
        except Exception as e:
            print(f"âœ— CUDA kernelæ‰§è¡Œå¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
    
    print("\nâœ“ lora_gate_forward ç®—å­æµ‹è¯•å®Œæˆ!")


def test_gate_weights_forward():
    """æµ‹è¯•gate_weights_forwardç®—å­"""
    print("\n" + "=" * 60)
    print("æµ‹è¯• gate_weights_forward ç®—å­")
    print("=" * 60)
    
    if not CUDA_KERNELS_AVAILABLE:
        print("âš ï¸  CUDA kernelsä¸å¯ç”¨ï¼Œè·³è¿‡æµ‹è¯•")
        return
    
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    
    # æµ‹è¯•å‚æ•°
    test_cases = [
        {"batch_size": 32, "gate_dim": 256, "num_experts": 5, "use_softmax": True},
        {"batch_size": 64, "gate_dim": 512, "num_experts": 8, "use_softmax": True},
        {"batch_size": 128, "gate_dim": 128, "num_experts": 3, "use_softmax": False},
        {"batch_size": 4096, "gate_dim": 700, "num_experts": 5, "use_softmax": True},  # é«˜ååé‡æµ‹è¯•ç”¨ä¾‹
    ]
    
    for i, case in enumerate(test_cases):
        print(f"\næµ‹è¯•ç”¨ä¾‹ {i+1}: {case}")
        print("-" * 40)
        
        batch_size = case["batch_size"]
        gate_dim = case["gate_dim"]
        num_experts = case["num_experts"]
        use_softmax = case["use_softmax"]
        
        # å¯¹äºé«˜ååé‡æµ‹è¯•ç”¨ä¾‹ï¼Œæ˜¾ç¤ºå†…å­˜ä½¿ç”¨æƒ…å†µ
        if batch_size >= 4096:
            print(f"  ğŸš€ é«˜ååé‡æµ‹è¯•ç”¨ä¾‹ - é¢„è®¡å†…å­˜ä½¿ç”¨: {batch_size * gate_dim * 4 / 1024**2:.1f} MB (è¾“å…¥)")
            print_gpu_memory()
        
        # åˆ›å»ºæµ‹è¯•æ•°æ®
        torch.manual_seed(42)
        gate_states = torch.randn(batch_size, gate_dim, device=device)
        gate_weights = torch.randn(gate_dim, num_experts, device=device)
        
        # æµ‹è¯•CUDA kernel
        try:
            with torch.no_grad():
                cuda_output = home_kernels.gate_weights_forward(
                    gate_states, gate_weights, use_softmax
                )
            
            print(f"âœ“ CUDA kernelæ‰§è¡ŒæˆåŠŸ")
            print(f"  è¾“å‡ºå½¢çŠ¶: {cuda_output.shape}")
            print(f"  è¾“å‡ºæ•°æ®ç±»å‹: {cuda_output.dtype}")
            print(f"  è¾“å‡ºè®¾å¤‡: {cuda_output.device}")
            
            # éªŒè¯è¾“å‡ºå½¢çŠ¶
            expected_shape = (batch_size, num_experts)
            if cuda_output.shape == expected_shape:
                print(f"âœ“ è¾“å‡ºå½¢çŠ¶æ­£ç¡®: {cuda_output.shape}")
            else:
                print(f"âœ— è¾“å‡ºå½¢çŠ¶é”™è¯¯: æœŸæœ› {expected_shape}, å®é™… {cuda_output.shape}")
            
            # ä¸PyTorchå®ç°å¯¹æ¯”éªŒè¯
            with torch.no_grad():
                pytorch_output = torch.matmul(gate_states, gate_weights)
                if use_softmax:
                    pytorch_output = torch.softmax(pytorch_output, dim=-1)
            
            # è®¡ç®—æ•°å€¼å·®å¼‚
            diff = torch.abs(cuda_output - pytorch_output)
            max_diff = torch.max(diff).item()
            mean_diff = torch.mean(diff).item()
            
            print(f"  ä¸PyTorchå®ç°å¯¹æ¯”:")
            print(f"    æœ€å¤§å·®å¼‚: {max_diff:.6f}")
            print(f"    å¹³å‡å·®å¼‚: {mean_diff:.6f}")
            
            if max_diff < 1e-4:
                print(f"âœ“ æ•°å€¼ç²¾åº¦éªŒè¯é€šè¿‡")
            else:
                print(f"âš ï¸  æ•°å€¼ç²¾åº¦å¯èƒ½å­˜åœ¨å·®å¼‚")
            
            # éªŒè¯softmaxç‰¹æ€§ï¼ˆå¦‚æœå¯ç”¨ï¼‰
            if use_softmax:
                row_sums = torch.sum(cuda_output, dim=-1)
                print(f"  SoftmaxéªŒè¯:")
                print(f"    è¡Œå’ŒèŒƒå›´: [{torch.min(row_sums).item():.6f}, {torch.max(row_sums).item():.6f}]")
                if torch.allclose(row_sums, torch.ones_like(row_sums), atol=1e-5):
                    print(f"    âœ“ Softmaxå½’ä¸€åŒ–æ­£ç¡®")
                else:
                    print(f"    âœ— Softmaxå½’ä¸€åŒ–å¯èƒ½æœ‰é—®é¢˜")
            
            # æ€§èƒ½æµ‹è¯•
            times = []
            num_runs = 10
            
            # é¢„çƒ­
            for _ in range(3):
                with torch.no_grad():
                    _ = home_kernels.gate_weights_forward(gate_states, gate_weights, use_softmax)
            
            # æµ‹è¯•
            for _ in range(num_runs):
                torch.cuda.synchronize()
                start_time = time.time()
                
                with torch.no_grad():
                    _ = home_kernels.gate_weights_forward(gate_states, gate_weights, use_softmax)
                
                torch.cuda.synchronize()
                end_time = time.time()
                times.append((end_time - start_time) * 1000)
            
            avg_time = sum(times) / len(times)
            min_time = min(times)
            max_time = max(times)
            std_time = (sum((t - avg_time) ** 2 for t in times) / len(times)) ** 0.5
            
            print(f"  æ€§èƒ½ç»Ÿè®¡:")
            print(f"    å¹³å‡æ—¶é—´: {avg_time:.4f} ms")
            print(f"    æœ€å°æ—¶é—´: {min_time:.4f} ms")
            print(f"    æœ€å¤§æ—¶é—´: {max_time:.4f} ms")
            print(f"    æ ‡å‡†å·®: {std_time:.4f} ms")
            
            # å¯¹äºé«˜ååé‡æµ‹è¯•ç”¨ä¾‹ï¼Œè®¡ç®—ååé‡
            if batch_size >= 4096:
                throughput = batch_size / (avg_time / 1000)  # samples per second
                print(f"    ååé‡: {throughput:.0f} samples/sec")
                print_gpu_memory()
            
        except Exception as e:
            print(f"âœ— CUDA kernelæ‰§è¡Œå¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
    
    print("\nâœ“ gate_weights_forward ç®—å­æµ‹è¯•å®Œæˆ!")


def test_expert_weighted_sum_forward():
    """æµ‹è¯•expert_weighted_sum_forwardç®—å­"""
    print("\n" + "=" * 60)
    print("æµ‹è¯• expert_weighted_sum_forward ç®—å­")
    print("=" * 60)
    
    if not CUDA_KERNELS_AVAILABLE:
        print("âš ï¸  CUDA kernelsä¸å¯ç”¨ï¼Œè·³è¿‡æµ‹è¯•")
        return
    
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    
    # æµ‹è¯•å‚æ•°
    test_cases = [
        {"batch_size": 32, "hidden_dim": 256, "num_experts": 5},
        {"batch_size": 64, "hidden_dim": 512, "num_experts": 8},
        {"batch_size": 128, "hidden_dim": 128, "num_experts": 3},
        {"batch_size": 4096, "hidden_dim": 256, "num_experts": 5},  # é«˜ååé‡æµ‹è¯•ç”¨ä¾‹
    ]
    
    for i, case in enumerate(test_cases):
        print(f"\næµ‹è¯•ç”¨ä¾‹ {i+1}: {case}")
        print("-" * 40)
        
        batch_size = case["batch_size"]
        hidden_dim = case["hidden_dim"]
        num_experts = case["num_experts"]
        
        # å¯¹äºé«˜ååé‡æµ‹è¯•ç”¨ä¾‹ï¼Œæ˜¾ç¤ºå†…å­˜ä½¿ç”¨æƒ…å†µ
        if batch_size >= 4096:
            print(f"  ğŸš€ é«˜ååé‡æµ‹è¯•ç”¨ä¾‹ - é¢„è®¡å†…å­˜ä½¿ç”¨: {batch_size * hidden_dim * num_experts * 4 / 1024**2:.1f} MB (ä¸“å®¶è¾“å‡º)")
            print_gpu_memory()
        
        # åˆ›å»ºæµ‹è¯•æ•°æ®
        torch.manual_seed(42)
        expert_outputs = torch.randn(batch_size, hidden_dim, num_experts, device=device)
        gate_weights = torch.randn(batch_size, num_experts, device=device)
        
        # æµ‹è¯•CUDA kernel
        try:
            with torch.no_grad():
                cuda_output = home_kernels.expert_weighted_sum_forward(
                    expert_outputs, gate_weights
                )
            
            print(f"âœ“ CUDA kernelæ‰§è¡ŒæˆåŠŸ")
            print(f"  è¾“å‡ºå½¢çŠ¶: {cuda_output.shape}")
            print(f"  è¾“å‡ºæ•°æ®ç±»å‹: {cuda_output.dtype}")
            print(f"  è¾“å‡ºè®¾å¤‡: {cuda_output.device}")
            
            # éªŒè¯è¾“å‡ºå½¢çŠ¶
            expected_shape = (batch_size, hidden_dim)
            if cuda_output.shape == expected_shape:
                print(f"âœ“ è¾“å‡ºå½¢çŠ¶æ­£ç¡®: {cuda_output.shape}")
            else:
                print(f"âœ— è¾“å‡ºå½¢çŠ¶é”™è¯¯: æœŸæœ› {expected_shape}, å®é™… {cuda_output.shape}")
            
            # ä¸PyTorchå®ç°å¯¹æ¯”éªŒè¯
            with torch.no_grad():
                # æ‰©å±•gate_weightsç»´åº¦ä»¥åŒ¹é…expert_outputs
                gate_weights_expanded = gate_weights.unsqueeze(1)  # [batch_size, 1, num_experts]
                pytorch_output = torch.sum(expert_outputs * gate_weights_expanded, dim=2)
            
            # è®¡ç®—æ•°å€¼å·®å¼‚
            diff = torch.abs(cuda_output - pytorch_output)
            max_diff = torch.max(diff).item()
            mean_diff = torch.mean(diff).item()
            
            print(f"  ä¸PyTorchå®ç°å¯¹æ¯”:")
            print(f"    æœ€å¤§å·®å¼‚: {max_diff:.6f}")
            print(f"    å¹³å‡å·®å¼‚: {mean_diff:.6f}")
            
            if max_diff < 1e-4:
                print(f"âœ“ æ•°å€¼ç²¾åº¦éªŒè¯é€šè¿‡")
            else:
                print(f"âš ï¸  æ•°å€¼ç²¾åº¦å¯èƒ½å­˜åœ¨å·®å¼‚")
            
            # æ€§èƒ½æµ‹è¯•
            times = []
            num_runs = 10
            
            # é¢„çƒ­
            for _ in range(3):
                with torch.no_grad():
                    _ = home_kernels.expert_weighted_sum_forward(expert_outputs, gate_weights)
            
            # æµ‹è¯•
            for _ in range(num_runs):
                torch.cuda.synchronize()
                start_time = time.time()
                
                with torch.no_grad():
                    _ = home_kernels.expert_weighted_sum_forward(expert_outputs, gate_weights)
                
                torch.cuda.synchronize()
                end_time = time.time()
                times.append((end_time - start_time) * 1000)
            
            avg_time = sum(times) / len(times)
            min_time = min(times)
            max_time = max(times)
            std_time = (sum((t - avg_time) ** 2 for t in times) / len(times)) ** 0.5
            
            print(f"  æ€§èƒ½ç»Ÿè®¡:")
            print(f"    å¹³å‡æ—¶é—´: {avg_time:.4f} ms")
            print(f"    æœ€å°æ—¶é—´: {min_time:.4f} ms")
            print(f"    æœ€å¤§æ—¶é—´: {max_time:.4f} ms")
            print(f"    æ ‡å‡†å·®: {std_time:.4f} ms")
            
            # å¯¹äºé«˜ååé‡æµ‹è¯•ç”¨ä¾‹ï¼Œè®¡ç®—ååé‡
            if batch_size >= 4096:
                throughput = batch_size / (avg_time / 1000)  # samples per second
                print(f"    ååé‡: {throughput:.0f} samples/sec")
                print_gpu_memory()
            
        except Exception as e:
            print(f"âœ— CUDA kernelæ‰§è¡Œå¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
    
    print("\nâœ“ expert_weighted_sum_forward ç®—å­æµ‹è¯•å®Œæˆ!")


def test_fused_batch_norm_silu_forward():
    """æµ‹è¯•fused_batch_norm_silu_forwardç®—å­"""
    print("\n" + "=" * 60)
    print("æµ‹è¯• fused_batch_norm_silu_forward ç®—å­")
    print("=" * 60)
    
    if not CUDA_KERNELS_AVAILABLE:
        print("âš ï¸  CUDA kernelsä¸å¯ç”¨ï¼Œè·³è¿‡æµ‹è¯•")
        return
    
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    
    # æµ‹è¯•å‚æ•°
    test_cases = [
        {"batch_size": 32, "num_experts": 5, "hidden_dim": 256},
        {"batch_size": 64, "num_experts": 8, "hidden_dim": 512},
        {"batch_size": 128, "num_experts": 3, "hidden_dim": 128},
        {"batch_size": 4096, "num_experts": 5, "hidden_dim": 256},  # é«˜ååé‡æµ‹è¯•ç”¨ä¾‹
    ]
    
    for i, case in enumerate(test_cases):
        print(f"\næµ‹è¯•ç”¨ä¾‹ {i+1}: {case}")
        print("-" * 40)
        
        batch_size = case["batch_size"]
        num_experts = case["num_experts"]
        hidden_dim = case["hidden_dim"]
        
        # å¯¹äºé«˜ååé‡æµ‹è¯•ç”¨ä¾‹ï¼Œæ˜¾ç¤ºå†…å­˜ä½¿ç”¨æƒ…å†µ
        if batch_size >= 4096:
            print(f"  ğŸš€ é«˜ååé‡æµ‹è¯•ç”¨ä¾‹ - é¢„è®¡å†…å­˜ä½¿ç”¨: {batch_size * num_experts * hidden_dim * 4 / 1024**2:.1f} MB (æ•°æ®)")
            print_gpu_memory()
        
        # åˆ›å»ºæµ‹è¯•æ•°æ®
        torch.manual_seed(42)
        data = torch.randn(batch_size, num_experts, hidden_dim, device=device)
        bn_weights = torch.randn(num_experts, hidden_dim, device=device)
        bn_biases = torch.randn(num_experts, hidden_dim, device=device)
        running_mean = torch.randn(num_experts, hidden_dim, device=device)
        running_var = torch.ones(num_experts, hidden_dim, device=device)  # ç¡®ä¿æ–¹å·®ä¸ºæ­£
        epsilon = 1e-5
        
        # æµ‹è¯•CUDA kernel
        try:
            with torch.no_grad():
                cuda_output = home_kernels.fused_batch_norm_silu_forward(
                    data, bn_weights, bn_biases, running_mean, running_var, epsilon
                )
            
            print(f"âœ“ CUDA kernelæ‰§è¡ŒæˆåŠŸ")
            print(f"  è¾“å‡ºå½¢çŠ¶: {cuda_output.shape}")
            print(f"  è¾“å‡ºæ•°æ®ç±»å‹: {cuda_output.dtype}")
            print(f"  è¾“å‡ºè®¾å¤‡: {cuda_output.device}")
            
            # éªŒè¯è¾“å‡ºå½¢çŠ¶
            expected_shape = (batch_size, num_experts, hidden_dim)
            if cuda_output.shape == expected_shape:
                print(f"âœ“ è¾“å‡ºå½¢çŠ¶æ­£ç¡®: {cuda_output.shape}")
            else:
                print(f"âœ— è¾“å‡ºå½¢çŠ¶é”™è¯¯: æœŸæœ› {expected_shape}, å®é™… {cuda_output.shape}")
            
            # ä¸PyTorchå®ç°å¯¹æ¯”éªŒè¯
            with torch.no_grad():
                # æ‰‹åŠ¨å®ç°BatchNorm + SiLU
                # é¦–å…ˆåº”ç”¨BatchNorm
                normalized = (data - running_mean.unsqueeze(0)) / torch.sqrt(running_var.unsqueeze(0) + epsilon)
                batch_norm_output = normalized * bn_weights.unsqueeze(0) + bn_biases.unsqueeze(0)
                
                # ç„¶ååº”ç”¨SiLUæ¿€æ´»å‡½æ•°
                pytorch_output = batch_norm_output * torch.sigmoid(batch_norm_output)
            
            # è®¡ç®—æ•°å€¼å·®å¼‚
            diff = torch.abs(cuda_output - pytorch_output)
            max_diff = torch.max(diff).item()
            mean_diff = torch.mean(diff).item()
            
            print(f"  ä¸PyTorchå®ç°å¯¹æ¯”:")
            print(f"    æœ€å¤§å·®å¼‚: {max_diff:.6f}")
            print(f"    å¹³å‡å·®å¼‚: {mean_diff:.6f}")
            
            if max_diff < 1e-4:
                print(f"âœ“ æ•°å€¼ç²¾åº¦éªŒè¯é€šè¿‡")
            else:
                print(f"âš ï¸  æ•°å€¼ç²¾åº¦å¯èƒ½å­˜åœ¨å·®å¼‚")
            
            # éªŒè¯SiLUæ¿€æ´»å‡½æ•°ç‰¹æ€§
            # SiLU(x) = x * sigmoid(x)ï¼Œåº”è¯¥ä¿æŒè¾“å…¥çš„æ­£è´Ÿæ€§
            input_positive = data > 0
            output_positive = cuda_output > 0
            consistency = torch.all(input_positive == output_positive)
            
            print(f"  SiLUæ¿€æ´»å‡½æ•°éªŒè¯:")
            print(f"    æ­£è´Ÿæ€§ä¸€è‡´æ€§: {'âœ“' if consistency else 'âœ—'}")
            
            # æ€§èƒ½æµ‹è¯•
            times = []
            num_runs = 10
            
            # é¢„çƒ­
            for _ in range(3):
                with torch.no_grad():
                    _ = home_kernels.fused_batch_norm_silu_forward(
                        data, bn_weights, bn_biases, running_mean, running_var, epsilon
                    )
            
            # æµ‹è¯•
            for _ in range(num_runs):
                torch.cuda.synchronize()
                start_time = time.time()
                
                with torch.no_grad():
                    _ = home_kernels.fused_batch_norm_silu_forward(
                        data, bn_weights, bn_biases, running_mean, running_var, epsilon
                    )
                
                torch.cuda.synchronize()
                end_time = time.time()
                times.append((end_time - start_time) * 1000)
            
            avg_time = sum(times) / len(times)
            min_time = min(times)
            max_time = max(times)
            std_time = (sum((t - avg_time) ** 2 for t in times) / len(times)) ** 0.5
            
            print(f"  æ€§èƒ½ç»Ÿè®¡:")
            print(f"    å¹³å‡æ—¶é—´: {avg_time:.4f} ms")
            print(f"    æœ€å°æ—¶é—´: {min_time:.4f} ms")
            print(f"    æœ€å¤§æ—¶é—´: {max_time:.4f} ms")
            print(f"    æ ‡å‡†å·®: {std_time:.4f} ms")
            
            # å¯¹äºé«˜ååé‡æµ‹è¯•ç”¨ä¾‹ï¼Œè®¡ç®—ååé‡
            if batch_size >= 4096:
                throughput = batch_size / (avg_time / 1000)  # samples per second
                print(f"    ååé‡: {throughput:.0f} samples/sec")
                print_gpu_memory()
            
        except Exception as e:
            print(f"âœ— CUDA kernelæ‰§è¡Œå¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
    
    print("\nâœ“ fused_batch_norm_silu_forward ç®—å­æµ‹è¯•å®Œæˆ!")


def test_cuda_kernel_times():
    """æµ‹è¯•å„ä¸ªCUDA kernelçš„æ‰§è¡Œæ—¶é—´"""
    print("\n" + "=" * 60)
    print("CUDA Kernelæ€§èƒ½æµ‹è¯•")
    print("=" * 60)
    
    if not CUDA_KERNELS_AVAILABLE:
        print("âš ï¸  CUDA kernelsä¸å¯ç”¨ï¼Œè·³è¿‡æµ‹è¯•")
        return
    
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    batch_size = 32
    input_dim = 256
    hidden_dim = 256
    num_experts = 5
    
    # åˆ›å»ºæµ‹è¯•æ•°æ®
    torch.manual_seed(42)
    input_data = torch.randn(batch_size, input_dim, device=device)
    expert_weights = torch.randn(num_experts, input_dim, hidden_dim, device=device)
    expert_biases = torch.randn(num_experts, hidden_dim, device=device)
    expert_indices = torch.arange(num_experts, dtype=torch.int32, device=device)
    
    # æµ‹è¯•å„ä¸ªkernel
    kernels_to_test = [
        ("home_expert_forward", lambda: home_kernels.home_expert_forward(
            input_data, expert_weights, expert_biases, expert_indices, num_experts, True
        )),
        ("lora_gate_forward", lambda: home_kernels.lora_gate_forward(
            input_data, torch.randn(input_dim, 16, device=device), 
            torch.randn(16, hidden_dim, device=device), True
        )),
        ("gate_weights_forward", lambda: home_kernels.gate_weights_forward(
            input_data, torch.randn(input_dim, num_experts, device=device), True
        )),
        ("expert_weighted_sum_forward", lambda: home_kernels.expert_weighted_sum_forward(
            torch.randn(batch_size, hidden_dim, num_experts, device=device),
            torch.randn(batch_size, num_experts, device=device)
        )),
        ("fused_batch_norm_silu_forward", lambda: home_kernels.fused_batch_norm_silu_forward(
            torch.randn(batch_size, num_experts, hidden_dim, device=device),
            torch.randn(num_experts, hidden_dim, device=device),
            torch.randn(num_experts, hidden_dim, device=device),
            torch.randn(num_experts, hidden_dim, device=device),
            torch.randn(num_experts, hidden_dim, device=device),
            1e-5
        ))
    ]
    
    print(f"{'Kernelåç§°':<30} {'å¹³å‡æ—¶é—´(ms)':<15} {'æœ€å°æ—¶é—´(ms)':<15} {'æœ€å¤§æ—¶é—´(ms)':<15} {'æ ‡å‡†å·®(ms)':<15}")
    print("-" * 90)
    
    for kernel_name, kernel_func in kernels_to_test:
        times = []
        num_runs = 10
        
        # é¢„çƒ­
        for _ in range(3):
            with torch.no_grad():
                _ = kernel_func()
        
        # æµ‹è¯•
        for _ in range(num_runs):
            torch.cuda.synchronize()
            start_time = time.time()
            
            with torch.no_grad():
                _ = kernel_func()
            
            torch.cuda.synchronize()
            end_time = time.time()
            times.append((end_time - start_time) * 1000)  # è½¬æ¢ä¸ºæ¯«ç§’
        
        # è®¡ç®—ç»Ÿè®¡ä¿¡æ¯
        avg_time = sum(times) / len(times)
        min_time = min(times)
        max_time = max(times)
        std_time = (sum((t - avg_time) ** 2 for t in times) / len(times)) ** 0.5
        
        print(f"{kernel_name:<30} {avg_time:<15.4f} {min_time:<15.4f} {max_time:<15.4f} {std_time:<15.4f}")

def profile_model_operators(model, input_states, l_gate_states, g_gate_states, l_gate_states_task, model_name="æ¨¡å‹"):
    """åˆ†ææ¨¡å‹å†…éƒ¨ç®—å­çš„æ‰§è¡Œæ—¶é—´"""
    print(f"\n{model_name}ç®—å­æ—¶é—´åˆ†æ:")
    print("-" * 50)
    
    # é¢„çƒ­
    with torch.no_grad():
        _ = model(input_states, l_gate_states, g_gate_states, l_gate_states_task)
    
    # ä½¿ç”¨torch.profilerè¿›è¡Œè¯¦ç»†åˆ†æ
    with torch.profiler.profile(
        activities=[torch.profiler.ProfilerActivity.CPU, torch.profiler.ProfilerActivity.CUDA],
        record_shapes=True,
        with_stack=True,
        profile_memory=True
    ) as prof:
        with torch.no_grad():
            _ = model(input_states, l_gate_states, g_gate_states, l_gate_states_task)
    
    # åˆ†æç»“æœ
    print("CUDAç®—å­ç»Ÿè®¡:")
    cuda_events = [event for event in prof.events() if event.device_type == torch.profiler.ProfilerActivity.CUDA]
    
    # æŒ‰ç®—å­ç±»å‹åˆ†ç»„ç»Ÿè®¡
    operator_stats = {}
    for event in cuda_events:
        op_name = event.name
        if op_name not in operator_stats:
            operator_stats[op_name] = {
                'count': 0,
                'total_time': 0,
                'avg_time': 0,
                'max_time': 0,
                'min_time': float('inf')
            }
        
        stats = operator_stats[op_name]
        stats['count'] += 1
        stats['total_time'] += event.cuda_time
        stats['max_time'] = max(stats['max_time'], event.cuda_time)
        stats['min_time'] = min(stats['min_time'], event.cuda_time)
    
    # è®¡ç®—å¹³å‡å€¼
    for op_name, stats in operator_stats.items():
        stats['avg_time'] = stats['total_time'] / stats['count']
        if stats['min_time'] == float('inf'):
            stats['min_time'] = 0
    
    # æŒ‰æ€»æ—¶é—´æ’åº
    sorted_ops = sorted(operator_stats.items(), key=lambda x: x[1]['total_time'], reverse=True)
    
    print(f"{'ç®—å­åç§°':<40} {'è°ƒç”¨æ¬¡æ•°':<8} {'æ€»æ—¶é—´(Î¼s)':<12} {'å¹³å‡æ—¶é—´(Î¼s)':<12} {'æœ€å¤§æ—¶é—´(Î¼s)':<12} {'æœ€å°æ—¶é—´(Î¼s)':<12}")
    print("-" * 100)
    
    total_cuda_time = 0
    for op_name, stats in sorted_ops[:20]:  # æ˜¾ç¤ºå‰20ä¸ªæœ€è€—æ—¶çš„ç®—å­
        print(f"{op_name:<40} {stats['count']:<8} {stats['total_time']:<12.2f} {stats['avg_time']:<12.2f} {stats['max_time']:<12.2f} {stats['min_time']:<12.2f}")
        total_cuda_time += stats['total_time']
    
    print("-" * 100)
    print(f"æ€»CUDAæ—¶é—´: {total_cuda_time:.2f} Î¼s ({total_cuda_time/1000:.2f} ms)")
    
    # åˆ†æå†…å­˜ä½¿ç”¨
    print(f"\nå†…å­˜ä½¿ç”¨åˆ†æ:")
    memory_events = [event for event in prof.events() if 'memory' in event.name.lower()]
    if memory_events:
        total_memory = sum(event.cuda_memory_usage for event in memory_events if hasattr(event, 'cuda_memory_usage'))
        print(f"æ€»å†…å­˜ä½¿ç”¨: {total_memory / 1024**2:.2f} MB")
    
    return operator_stats

def quick_operator_analysis(model, input_states, l_gate_states, g_gate_states, l_gate_states_task, model_name="æ¨¡å‹"):
    """å¿«é€Ÿç®—å­åˆ†æï¼ˆä¸ä½¿ç”¨profilerï¼Œé¿å…å¼€é”€ï¼‰"""
    print(f"\n{model_name}å¿«é€Ÿç®—å­åˆ†æ:")
    print("-" * 40)
    
    # é¢„çƒ­
    with torch.no_grad():
        _ = model(input_states, l_gate_states, g_gate_states, l_gate_states_task)
    
    # å¤šæ¬¡è¿è¡Œæµ‹è¯•æ€»æ—¶é—´
    num_runs = 5
    times = []
    
    for i in range(num_runs):
        torch.cuda.synchronize() if torch.cuda.is_available() else None
        start_time = time.time()
        
        with torch.no_grad():
            _ = model(input_states, l_gate_states, g_gate_states, l_gate_states_task)
        
        torch.cuda.synchronize() if torch.cuda.is_available() else None
        end_time = time.time()
        times.append((end_time - start_time) * 1000)  # è½¬æ¢ä¸ºæ¯«ç§’
    
    avg_time = sum(times) / len(times)
    min_time = min(times)
    max_time = max(times)
    std_time = (sum((t - avg_time) ** 2 for t in times) / len(times)) ** 0.5
    
    print(f"æ€»æ¨ç†æ—¶é—´: {avg_time:.2f} Â± {std_time:.2f} ms")
    print(f"æ—¶é—´èŒƒå›´: {min_time:.2f} - {max_time:.2f} ms")
    
    return avg_time

def detailed_operator_analysis():
    """è¯¦ç»†çš„ç®—å­åˆ†æï¼Œä½¿ç”¨torch.profiler"""
    print("\n" + "=" * 60)
    print("è¯¦ç»†ç®—å­åˆ†æ")
    print("=" * 60)
    
    if not CUDA_KERNELS_AVAILABLE:
        print("âš ï¸  CUDA kernelsä¸å¯ç”¨ï¼Œè·³è¿‡è¯¦ç»†åˆ†æ")
        return
    
    try:
        from HoME_optimized import HoMELayerOptimized
        from HoME import HoMELayer
    except ImportError as e:
        print(f"âœ— å¯¼å…¥å¤±è´¥: {e}")
        return
    
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    
    # æ¨¡å‹é…ç½®
    config = {
        'num_experts': 5,
        'input_dims': [700] * 6,
        'dim': 256,
        'l_gate_dim': 700,
        'g_gate_dim': 700,
        'l_gate_dim_task': 700,
        'use_lora_gate': True,
        'lora_rank': 2
    }
    
    # åˆ›å»ºæµ‹è¯•æ•°æ®
    batch_size = 32
    input_states = [torch.randn(batch_size, 700, device=device) for _ in range(6)]
    l_gate_states = torch.randn(batch_size, 700, device=device)
    g_gate_states = torch.randn(batch_size, 700, device=device)
    l_gate_states_task = torch.randn(batch_size, 700, device=device)
    
    # åˆ†æåŸå§‹ç‰ˆæœ¬
    print("\nåˆ†æåŸå§‹ç‰ˆæœ¬è¯¦ç»†ç®—å­...")
    try:
        torch.manual_seed(42)
        model_original = HoMELayer(**config).to(device)
        
        orig_stats = profile_model_operators(
            model_original, input_states, l_gate_states, g_gate_states, l_gate_states_task, "åŸå§‹ç‰ˆæœ¬"
        )
        
        del model_original
        clear_gpu_memory()
        
    except Exception as e:
        print(f"âœ— åŸå§‹ç‰ˆæœ¬è¯¦ç»†åˆ†æå¤±è´¥: {e}")
        orig_stats = {}
    
    # åˆ†æä¼˜åŒ–ç‰ˆæœ¬
    print("\nåˆ†æä¼˜åŒ–ç‰ˆæœ¬è¯¦ç»†ç®—å­...")
    try:
        torch.manual_seed(42)
        model_optimized = HoMELayerOptimized(**config, use_cuda_kernels=True).to(device)
        
        opt_stats = profile_model_operators(
            model_optimized, input_states, l_gate_states, g_gate_states, l_gate_states_task, "ä¼˜åŒ–ç‰ˆæœ¬"
        )
        
    except Exception as e:
        print(f"âœ— ä¼˜åŒ–ç‰ˆæœ¬è¯¦ç»†åˆ†æå¤±è´¥: {e}")
        opt_stats = {}
    
    # å¯¹æ¯”åˆ†æ
    if orig_stats and opt_stats:
        print("\nç®—å­å¯¹æ¯”åˆ†æ:")
        print("-" * 60)
        
        # æ‰¾å‡ºå…±åŒçš„ç®—å­
        common_ops = set(orig_stats.keys()) & set(opt_stats.keys())
        
        print(f"{'ç®—å­åç§°':<30} {'åŸå§‹ç‰ˆæœ¬(Î¼s)':<15} {'ä¼˜åŒ–ç‰ˆæœ¬(Î¼s)':<15} {'åŠ é€Ÿæ¯”':<10}")
        print("-" * 70)
        
        for op_name in sorted(common_ops):
            orig_time = orig_stats[op_name]['total_time']
            opt_time = opt_stats[op_name]['total_time']
            speedup = orig_time / opt_time if opt_time > 0 else float('inf')
            
            print(f"{op_name:<30} {orig_time:<15.2f} {opt_time:<15.2f} {speedup:<10.2f}x")
    
    print("\nâœ“ è¯¦ç»†ç®—å­åˆ†æå®Œæˆ!")

def sync_model_weights(model_original, model_optimized):
    """åŒæ­¥ä¸¤ä¸ªæ¨¡å‹çš„æƒé‡ï¼Œç¡®ä¿å®Œå…¨ä¸€è‡´"""
    print("å¼€å§‹æƒé‡åŒæ­¥...")
    
    # 1. åŒæ­¥LoRAé—¨æ§æƒé‡
    if hasattr(model_original, 'group_f_gates') and hasattr(model_optimized, 'group_f_gates'):
        for key in model_original.group_f_gates.keys():
            if key in model_optimized.group_f_gates:
                # åŒæ­¥Aå’ŒBçŸ©é˜µ
                model_optimized.group_f_gates[key].A.data.copy_(model_original.group_f_gates[key].A.data)
                model_optimized.group_f_gates[key].B.data.copy_(model_original.group_f_gates[key].B.data)
                print(f"  åŒæ­¥LoRAé—¨æ§: {key}")
    
    # 2. åŒæ­¥ä¸“å®¶ç½‘ç»œæƒé‡
    if hasattr(model_original, 'task_experts') and hasattr(model_optimized, 'task_experts'):
        for task_key in model_original.task_experts.keys():
            if task_key in model_optimized.task_experts:
                orig_experts = model_original.task_experts[task_key]
                opt_expert = model_optimized.task_experts[task_key]
                
                # ä»åŸå§‹ç‰ˆæœ¬çš„ä¸“å®¶ç½‘ç»œä¸­æå–æƒé‡
                expert_weights_list = []
                expert_biases_list = []
                
                for i, orig_expert in enumerate(orig_experts):
                    # åŸå§‹ç‰ˆæœ¬æ˜¯Sequential(MLPLayer, BatchNorm, SiLU)
                    mlp_layer = orig_expert[0]  # MLPLayer
                    
                    # è·å–MLPå±‚çš„æƒé‡å’Œåç½®
                    if hasattr(mlp_layer, 'layers') and len(mlp_layer.layers) > 0:
                        # MLPLayerçš„ç¬¬ä¸€å±‚æ˜¯Linearå±‚
                        linear_layer = mlp_layer.layers[0]
                        expert_weights_list.append(linear_layer.weight.data.t())  # è½¬ç½®ä¸º[input_dim, output_dim]
                        if linear_layer.bias is not None:
                            expert_biases_list.append(linear_layer.bias.data)
                        else:
                            expert_biases_list.append(torch.zeros(linear_layer.weight.size(0), device=linear_layer.weight.device))
                
                if expert_weights_list:
                    # å°†æƒé‡å †å ä¸º[num_experts, input_dim, output_dim]
                    stacked_weights = torch.stack(expert_weights_list, dim=0)
                    stacked_biases = torch.stack(expert_biases_list, dim=0)
                    
                    # åŒæ­¥åˆ°ä¼˜åŒ–ç‰ˆæœ¬
                    opt_expert.expert_weights.data.copy_(stacked_weights)
                    opt_expert.expert_biases.data.copy_(stacked_biases)
                    print(f"  åŒæ­¥ä¸“å®¶æƒé‡: {task_key} - {len(expert_weights_list)} experts")
    
    # 3. åŒæ­¥é—¨æ§ç½‘ç»œæƒé‡
    if hasattr(model_original, 'task_l_gates') and hasattr(model_optimized, 'task_l_gates'):
        for key in model_original.task_l_gates.keys():
            if key in model_optimized.task_l_gates:
                # åŒæ­¥é—¨æ§ç½‘ç»œçš„æƒé‡
                orig_gate = model_original.task_l_gates[key]
                opt_gate = model_optimized.task_l_gates[key]
                
                # è·å–åŸå§‹é—¨æ§çš„æƒé‡
                if hasattr(orig_gate, 'layers') and len(orig_gate.layers) > 0:
                    orig_linear = orig_gate.layers[0]  # DenseLayerçš„ç¬¬ä¸€å±‚æ˜¯Linear
                    opt_gate.gate_weights.data.copy_(orig_gate.layers[0].weight.data)
                    if orig_linear.bias is not None:
                        opt_gate.gate_biases.data.copy_(orig_linear.bias.data)
                    print(f"  åŒæ­¥é—¨æ§æƒé‡: {key}")
    
    # 4. åŒæ­¥gé—¨æ§æƒé‡
    if hasattr(model_original, 'task_g_gates') and hasattr(model_optimized, 'task_g_gates'):
        for key in model_original.task_g_gates.keys():
            if key in model_optimized.task_g_gates:
                orig_gate = model_original.task_g_gates[key]
                opt_gate = model_optimized.task_g_gates[key]
                
                if hasattr(orig_gate, 'layers') and len(orig_gate.layers) > 0:
                    orig_linear = orig_gate.layers[0]
                    opt_gate.gate_weights.data.copy_(orig_linear.weight.data)
                    if orig_linear.bias is not None:
                        opt_gate.gate_biases.data.copy_(orig_linear.bias.data)
                    print(f"  åŒæ­¥gé—¨æ§æƒé‡: {key}")
    
    # 5. åŒæ­¥metaä¸“å®¶æƒé‡
    if hasattr(model_original, 'meta_specific_experts') and hasattr(model_optimized, 'meta_experts'):
        for group_name in model_original.meta_specific_experts.keys():
            if group_name in model_optimized.meta_experts:
                orig_experts = model_original.meta_specific_experts[group_name]
                opt_expert = model_optimized.meta_experts[group_name]
                
                # æå–metaä¸“å®¶æƒé‡
                meta_weights_list = []
                meta_biases_list = []
                
                for orig_expert in orig_experts:
                    mlp_layer = orig_expert[0]  # MLPLayer
                    if hasattr(mlp_layer, 'layers') and len(mlp_layer.layers) > 0:
                        linear_layer = mlp_layer.layers[0]
                        meta_weights_list.append(linear_layer.weight.data.t())
                        if linear_layer.bias is not None:
                            meta_biases_list.append(linear_layer.bias.data)
                        else:
                            meta_biases_list.append(torch.zeros(linear_layer.weight.size(0), device=linear_layer.weight.device))
                
                if meta_weights_list:
                    stacked_weights = torch.stack(meta_weights_list, dim=0)
                    stacked_biases = torch.stack(meta_biases_list, dim=0)
                    
                    opt_expert.expert_weights.data.copy_(stacked_weights)
                    opt_expert.expert_biases.data.copy_(stacked_biases)
                    print(f"  åŒæ­¥metaä¸“å®¶æƒé‡: {group_name}")
    
    print("æƒé‡åŒæ­¥å®Œæˆï¼")


def example_basic_usage():
    """åŸºæœ¬ä½¿ç”¨ç¤ºä¾‹"""
    print("=" * 60)
    print("HoMEä¼˜åŒ–æ¶æ„åŸºæœ¬ä½¿ç”¨ç¤ºä¾‹")
    print("=" * 60)
    
    try:
        from HoME_optimized import HoMELayerOptimized
        print("âœ“ æˆåŠŸå¯¼å…¥HoME_optimizedæ¨¡å—")
    except ImportError as e:
        print(f"âœ— å¯¼å…¥å¤±è´¥: {e}")
        print("è¯·å…ˆç¼–è¯‘CUDA kernel: python setup_home_optimized.py build_ext --inplace")
        return
    
    # æ£€æŸ¥è®¾å¤‡
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    print(f"ä½¿ç”¨è®¾å¤‡: {device}")
    
    # åˆ›å»ºæ¨¡å‹
    print("\nåˆ›å»ºHoMEæ¨¡å‹...")
    try:
        model = HoMELayerOptimized(
            num_experts=5,                    # ä¸“å®¶æ•°é‡
            input_dims=[700] * 6,  # å„ä»»åŠ¡è¾“å…¥ç»´åº¦
            dim=256,                          # éšè—ç»´åº¦
            l_gate_dim=700,                   # lé—¨æ§ç»´åº¦
            g_gate_dim=700,                   # gé—¨æ§ç»´åº¦
            l_gate_dim_task=700,               # ä»»åŠ¡çº§lé—¨æ§ç»´åº¦
            use_lora_gate=True,               # ä½¿ç”¨LoRAé—¨æ§
            lora_rank=2,                     # LoRAç§©
            use_cuda_kernels=CUDA_KERNELS_AVAILABLE  # æ ¹æ®å¯ç”¨æ€§å†³å®šæ˜¯å¦ä½¿ç”¨CUDA kernel
        ).to(device)
        
        print(f"æ¨¡å‹å‚æ•°æ•°é‡: {sum(p.numel() for p in model.parameters()):,}")
    except Exception as e:
        print(f"âœ— æ¨¡å‹åˆ›å»ºå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return
    
    # åˆ›å»ºç¤ºä¾‹æ•°æ®
    print("\nåˆ›å»ºç¤ºä¾‹æ•°æ®...")
    input_states, l_gate_states, g_gate_states, l_gate_states_task = create_sample_data(
        batch_size=32, device=device
    )
    
    # å‰å‘ä¼ æ’­
    print("\næ‰§è¡Œå‰å‘ä¼ æ’­...")
    try:
        with torch.no_grad():
            start_time = time.time()
            outputs = model(input_states, l_gate_states, g_gate_states, l_gate_states_task)
            inference_time = time.time() - start_time
        
        print(f"æ¨ç†æ—¶é—´: {inference_time*1000:.2f} ms")
        
        # æ˜¾ç¤ºè¾“å‡º
        print("\næ¨¡å‹è¾“å‡º:")
        for key, output in outputs.items():
            print(f"  {key}: {output.shape}")
        
        print("\nâœ“ åŸºæœ¬ä½¿ç”¨ç¤ºä¾‹å®Œæˆ!")
        
    except Exception as e:
        print(f"âœ— å‰å‘ä¼ æ’­å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return


def compare_home_versions():
    """å¯¹æ¯”HoMELayerOptimizedå’ŒHoMELayerçš„ç²¾åº¦å’Œæ€§èƒ½"""
    print("\n" + "=" * 60)
    print("HoMEç‰ˆæœ¬å¯¹æ¯”æµ‹è¯•")
    print("=" * 60)
    
    try:
        from HoME_optimized import HoMELayerOptimized
        from HoME import HoMELayer
        print("âœ“ æˆåŠŸå¯¼å…¥ä¸¤ä¸ªHoMEç‰ˆæœ¬")
    except ImportError as e:
        print(f"âœ— å¯¼å…¥å¤±è´¥: {e}")
        return
    
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    print(f"ä½¿ç”¨è®¾å¤‡: {device}")
    
    # æ¨¡å‹é…ç½®
    config = {
        'num_experts': 5,
        'input_dims': [700] * 6,
        'dim': 256,
        'l_gate_dim': 700,
        'g_gate_dim': 700,
        'l_gate_dim_task': 700,
        'use_lora_gate': True,
        'lora_rank': 2
    }
    
    # åˆ›å»ºä¸¤ä¸ªç‰ˆæœ¬çš„æ¨¡å‹ï¼Œç¡®ä¿æƒé‡åˆå§‹åŒ–ç›¸åŒ
    print("\nåˆ›å»ºæ¨¡å‹...")
    print_gpu_memory()
    
    try:
        # ä½¿ç”¨ç›¸åŒçš„éšæœºç§å­åˆ›å»ºåŸå§‹ç‰ˆæœ¬
        torch.manual_seed(42)
        if torch.cuda.is_available():
            torch.cuda.manual_seed(42)
        model_original = HoMELayer(
            **config
        ).to(device)
        
        # ä½¿ç”¨ç›¸åŒçš„éšæœºç§å­åˆ›å»ºä¼˜åŒ–ç‰ˆæœ¬
        torch.manual_seed(42)
        if torch.cuda.is_available():
            torch.cuda.manual_seed(42)
        model_optimized = HoMELayerOptimized(
            **config,
            use_cuda_kernels=CUDA_KERNELS_AVAILABLE
        ).to(device)
        
        print(f"åŸå§‹ç‰ˆæœ¬å‚æ•°æ•°é‡: {sum(p.numel() for p in model_original.parameters()):,}")
        print(f"ä¼˜åŒ–ç‰ˆæœ¬å‚æ•°æ•°é‡: {sum(p.numel() for p in model_optimized.parameters()):,}")
        
        # æ‰‹åŠ¨åŒæ­¥æƒé‡ï¼ˆç¡®ä¿å®Œå…¨ä¸€è‡´ï¼‰
        print("åŒæ­¥æ¨¡å‹æƒé‡...")
        sync_model_weights(model_original, model_optimized)
        
        print_gpu_memory()
    except Exception as e:
        print(f"âœ— æ¨¡å‹åˆ›å»ºå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return
    
    # åˆ›å»ºæµ‹è¯•æ•°æ®
    print("\nåˆ›å»ºæµ‹è¯•æ•°æ®...")
    batch_size = 32
    input_states, l_gate_states, g_gate_states, l_gate_states_task = create_sample_data(
        batch_size=batch_size, device=device
    )
    
    # è®¾ç½®ç›¸åŒçš„éšæœºç§å­ç¡®ä¿å¯é‡å¤æ€§
    torch.manual_seed(42)
    if torch.cuda.is_available():
        torch.cuda.manual_seed(42)
    
    # é‡æ–°åˆ›å»ºæ•°æ®ä»¥ç¡®ä¿ä¸€è‡´æ€§
    input_states = [torch.randn(batch_size, 700, device=device) for _ in range(6)]
    l_gate_states = torch.randn(batch_size, 700, device=device)
    g_gate_states = torch.randn(batch_size, 700, device=device)
    l_gate_states_task = torch.randn(batch_size, 700, device=device)
    
    # ç²¾åº¦å¯¹æ¯”æµ‹è¯•
    print("\n" + "-" * 40)
    print("ç²¾åº¦å¯¹æ¯”æµ‹è¯•")
    print("-" * 40)
    
    # å…ˆæµ‹è¯•åŸå§‹ç‰ˆæœ¬
    print("æµ‹è¯•åŸå§‹ç‰ˆæœ¬...")
    outputs_original = None
    try:
        with torch.no_grad():
            outputs_original = model_original(input_states, l_gate_states, g_gate_states, l_gate_states_task)
        print("âœ“ åŸå§‹ç‰ˆæœ¬è¿è¡ŒæˆåŠŸ")
        print(f"åŸå§‹ç‰ˆæœ¬è¾“å‡ºé”®: {list(outputs_original.keys())}")
    except Exception as e:
        print(f"âœ— åŸå§‹ç‰ˆæœ¬è¿è¡Œå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return
    
    # æ¸…ç†GPUå†…å­˜
    if torch.cuda.is_available():
        del model_original
        clear_gpu_memory()
        print_gpu_memory()
    
    # å†æµ‹è¯•ä¼˜åŒ–ç‰ˆæœ¬
    print("\næµ‹è¯•ä¼˜åŒ–ç‰ˆæœ¬...")
    outputs_optimized = None
    try:
        with torch.no_grad():
            outputs_optimized = model_optimized(input_states, l_gate_states, g_gate_states, l_gate_states_task)
        print("âœ“ ä¼˜åŒ–ç‰ˆæœ¬è¿è¡ŒæˆåŠŸ")
        print(f"ä¼˜åŒ–ç‰ˆæœ¬è¾“å‡ºé”®: {list(outputs_optimized.keys())}")
    except Exception as e:
        print(f"âœ— ä¼˜åŒ–ç‰ˆæœ¬è¿è¡Œå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return
    
    # è¿›è¡Œç²¾åº¦å¯¹æ¯”
    print("\nè¿›è¡Œç²¾åº¦å¯¹æ¯”...")
    try:
        print("è¾“å‡ºå½¢çŠ¶å¯¹æ¯”:")
        for key in outputs_optimized.keys():
            if key in outputs_original:
                opt_shape = outputs_optimized[key].shape
                orig_shape = outputs_original[key].shape
                print(f"  {key}: ä¼˜åŒ–ç‰ˆæœ¬ {opt_shape} vs åŸå§‹ç‰ˆæœ¬ {orig_shape}")
                
                # è®¡ç®—æ•°å€¼å·®å¼‚
                if opt_shape == orig_shape:
                    diff = torch.abs(outputs_optimized[key] - outputs_original[key])
                    max_diff = torch.max(diff).item()
                    mean_diff = torch.mean(diff).item()
                    print(f"    æœ€å¤§å·®å¼‚: {max_diff:.6f}")
                    print(f"    å¹³å‡å·®å¼‚: {mean_diff:.6f}")
                    
                    # è®¡ç®—ç›¸å¯¹è¯¯å·®
                    rel_error = mean_diff / torch.mean(torch.abs(outputs_original[key])).item()
                    print(f"    ç›¸å¯¹è¯¯å·®: {rel_error:.6f}")
                else:
                    print(f"    âŒ å½¢çŠ¶ä¸åŒ¹é…!")
            else:
                print(f"  {key}: ä»…åœ¨ä¼˜åŒ–ç‰ˆæœ¬ä¸­å­˜åœ¨")
        
        # æ£€æŸ¥åŸå§‹ç‰ˆæœ¬ç‹¬æœ‰çš„è¾“å‡º
        for key in outputs_original.keys():
            if key not in outputs_optimized:
                print(f"  {key}: ä»…åœ¨åŸå§‹ç‰ˆæœ¬ä¸­å­˜åœ¨")
        
    except Exception as e:
        print(f"âœ— ç²¾åº¦å¯¹æ¯”å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return
    
    # å¿«é€Ÿç®—å­æ—¶é—´åˆ†æ
    print("\n" + "=" * 60)
    print("å¿«é€Ÿç®—å­æ—¶é—´åˆ†æ")
    print("=" * 60)
    
    # åˆ†æåŸå§‹ç‰ˆæœ¬ç®—å­æ—¶é—´
    print("\nåˆ†æåŸå§‹ç‰ˆæœ¬ç®—å­æ—¶é—´...")
    try:
        # é‡æ–°åˆ›å»ºåŸå§‹ç‰ˆæœ¬æ¨¡å‹ç”¨äºåˆ†æ
        torch.manual_seed(42)
        model_original_for_profile = HoMELayer(**config).to(device)
        sync_model_weights(model_original_for_profile, model_optimized)
        
        orig_avg_time = quick_operator_analysis(
            model_original_for_profile, input_states, l_gate_states, g_gate_states, l_gate_states_task, "åŸå§‹ç‰ˆæœ¬"
        )
        
        # æ¸…ç†å†…å­˜
        del model_original_for_profile
        clear_gpu_memory()
        
    except Exception as e:
        print(f"âœ— åŸå§‹ç‰ˆæœ¬ç®—å­åˆ†æå¤±è´¥: {e}")
        orig_avg_time = 0
    
    # åˆ†æä¼˜åŒ–ç‰ˆæœ¬ç®—å­æ—¶é—´
    print("\nåˆ†æä¼˜åŒ–ç‰ˆæœ¬ç®—å­æ—¶é—´...")
    try:
        opt_avg_time = quick_operator_analysis(
            model_optimized, input_states, l_gate_states, g_gate_states, l_gate_states_task, "ä¼˜åŒ–ç‰ˆæœ¬"
        )
    except Exception as e:
        print(f"âœ— ä¼˜åŒ–ç‰ˆæœ¬ç®—å­åˆ†æå¤±è´¥: {e}")
        opt_avg_time = 0
    
    # ç®—å­æ—¶é—´å¯¹æ¯”
    if orig_avg_time > 0 and opt_avg_time > 0:
        speedup = orig_avg_time / opt_avg_time
        print(f"\nç®—å­æ—¶é—´å¯¹æ¯”:")
        print(f"  åŸå§‹ç‰ˆæœ¬: {orig_avg_time:.2f} ms")
        print(f"  ä¼˜åŒ–ç‰ˆæœ¬: {opt_avg_time:.2f} ms")
        print(f"  åŠ é€Ÿæ¯”: {speedup:.2f}x")
        
        if speedup > 1:
            print(f"  âœ… ä¼˜åŒ–ç‰ˆæœ¬æ›´å¿«")
        else:
            print(f"  âš ï¸  åŸå§‹ç‰ˆæœ¬æ›´å¿«")
    
    # æ€§èƒ½å¯¹æ¯”æµ‹è¯•
    print("\n" + "-" * 40)
    print("æ€§èƒ½å¯¹æ¯”æµ‹è¯•")
    print("-" * 40)
    
    num_runs = 5  # å‡å°‘è¿è¡Œæ¬¡æ•°ä»¥èŠ‚çœå†…å­˜
    
    # å…ˆæµ‹è¯•åŸå§‹ç‰ˆæœ¬æ€§èƒ½
    print("æµ‹è¯•åŸå§‹ç‰ˆæœ¬æ€§èƒ½...")
    orig_time = float('inf')
    try:
        # é‡æ–°åˆ›å»ºåŸå§‹ç‰ˆæœ¬æ¨¡å‹
        model_original = HoMELayer(**config).to(device)
        
        # é¢„çƒ­
        for _ in range(2):
            with torch.no_grad():
                _ = model_original(input_states, l_gate_states, g_gate_states, l_gate_states_task)
        
        # æ€§èƒ½æµ‹è¯•
        torch.cuda.synchronize() if torch.cuda.is_available() else None
        start_time = time.time()
        
        with torch.no_grad():
            for _ in range(num_runs):
                _ = model_original(input_states, l_gate_states, g_gate_states, l_gate_states_task)
        
        torch.cuda.synchronize() if torch.cuda.is_available() else None
        orig_time = time.time() - start_time
        
        print(f"åŸå§‹ç‰ˆæœ¬å¹³å‡æ—¶é—´: {orig_time/num_runs*1000:.2f} ms")
        
    except Exception as e:
        print(f"âœ— åŸå§‹ç‰ˆæœ¬æ€§èƒ½æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
    
    # æ¸…ç†åŸå§‹ç‰ˆæœ¬æ¨¡å‹
    if torch.cuda.is_available():
        del model_original
        clear_gpu_memory()
        print_gpu_memory()
    
    # å†æµ‹è¯•ä¼˜åŒ–ç‰ˆæœ¬æ€§èƒ½
    print("\næµ‹è¯•ä¼˜åŒ–ç‰ˆæœ¬æ€§èƒ½...")
    opt_time = float('inf')
    try:
        # é¢„çƒ­
        for _ in range(2):
            with torch.no_grad():
                _ = model_optimized(input_states, l_gate_states, g_gate_states, l_gate_states_task)
        
        # æ€§èƒ½æµ‹è¯•
        torch.cuda.synchronize() if torch.cuda.is_available() else None
        start_time = time.time()
        
        with torch.no_grad():
            for _ in range(num_runs):
                _ = model_optimized(input_states, l_gate_states, g_gate_states, l_gate_states_task)
        
        torch.cuda.synchronize() if torch.cuda.is_available() else None
        opt_time = time.time() - start_time
        
        print(f"ä¼˜åŒ–ç‰ˆæœ¬å¹³å‡æ—¶é—´: {opt_time/num_runs*1000:.2f} ms")
        
    except Exception as e:
        print(f"âœ— ä¼˜åŒ–ç‰ˆæœ¬æ€§èƒ½æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
    
    # æ€§èƒ½å¯¹æ¯”ç»“æœ
    if opt_time != float('inf') and orig_time != float('inf'):
        speedup = orig_time / opt_time
        print(f"\næ€§èƒ½å¯¹æ¯”ç»“æœ:")
        print(f"  ä¼˜åŒ–ç‰ˆæœ¬: {opt_time/num_runs*1000:.2f} ms")
        print(f"  åŸå§‹ç‰ˆæœ¬: {orig_time/num_runs*1000:.2f} ms")
        print(f"  åŠ é€Ÿæ¯”: {speedup:.2f}x")
        
        if speedup > 1:
            print(f"  âœ… ä¼˜åŒ–ç‰ˆæœ¬æ›´å¿«")
        else:
            print(f"  âš ï¸  åŸå§‹ç‰ˆæœ¬æ›´å¿«")
    
    # å†…å­˜ä½¿ç”¨å¯¹æ¯”
    if torch.cuda.is_available():
        print(f"\nGPUå†…å­˜ä½¿ç”¨:")
        print(f"  å·²åˆ†é…: {torch.cuda.memory_allocated()/1024**3:.2f} GB")
        print(f"  å·²ç¼“å­˜: {torch.cuda.memory_reserved()/1024**3:.2f} GB")
    
    print("\nâœ“ HoMEç‰ˆæœ¬å¯¹æ¯”æµ‹è¯•å®Œæˆ!")


def run_comprehensive_kernel_tests():
    """è¿è¡Œæ‰€æœ‰CUDA kernelçš„è¯¦ç»†æµ‹è¯•"""
    print("\n" + "=" * 80)
    print("HoME CUDA Kernels ç»¼åˆæµ‹è¯•å¥—ä»¶")
    print("=" * 80)
    
    if not CUDA_KERNELS_AVAILABLE:
        print("âš ï¸  CUDA kernelsä¸å¯ç”¨ï¼Œè·³è¿‡æ‰€æœ‰kernelæµ‹è¯•")
        return
    
    # è¿è¡Œå„ä¸ªç®—å­çš„è¯¦ç»†æµ‹è¯•
    test_home_expert_forward()
    test_lora_gate_forward()
    test_gate_weights_forward()
    test_expert_weighted_sum_forward()
    test_fused_batch_norm_silu_forward()
    
    print("\n" + "=" * 80)
    print("æ‰€æœ‰CUDA kernelæµ‹è¯•å®Œæˆ!")
    print("=" * 80)


def run_performance_benchmark():
    """è¿è¡Œæ€§èƒ½åŸºå‡†æµ‹è¯•"""
    print("\n" + "=" * 80)
    print("HoME æ€§èƒ½åŸºå‡†æµ‹è¯•")
    print("=" * 80)
    
    if not CUDA_KERNELS_AVAILABLE:
        print("âš ï¸  CUDA kernelsä¸å¯ç”¨ï¼Œè·³è¿‡æ€§èƒ½æµ‹è¯•")
        return
    
    # è¿è¡Œå¿«é€Ÿæ€§èƒ½æµ‹è¯•
    test_cuda_kernel_times()
    
    # è¿è¡Œè¯¦ç»†ç®—å­åˆ†æ
    detailed_operator_analysis()
    
    print("\n" + "=" * 80)
    print("æ€§èƒ½åŸºå‡†æµ‹è¯•å®Œæˆ!")
    print("=" * 80)


def run_accuracy_validation():
    """è¿è¡Œç²¾åº¦éªŒè¯æµ‹è¯•"""
    print("\n" + "=" * 80)
    print("HoME ç²¾åº¦éªŒè¯æµ‹è¯•")
    print("=" * 80)
    
    # è¿è¡Œç‰ˆæœ¬å¯¹æ¯”æµ‹è¯•
    compare_home_versions()
    
    print("\n" + "=" * 80)
    print("ç²¾åº¦éªŒè¯æµ‹è¯•å®Œæˆ!")
    print("=" * 80)


def run_all_tests():
    """è¿è¡Œæ‰€æœ‰æµ‹è¯•"""
    print("HoMEä¼˜åŒ–æ¶æ„å®Œæ•´æµ‹è¯•å¥—ä»¶")
    print("=" * 80)
    
    # æ£€æŸ¥CUDAå¯ç”¨æ€§
    if torch.cuda.is_available():
        print(f"CUDAå¯ç”¨: {torch.cuda.get_device_name(0)}")
        print(f"CUDAç‰ˆæœ¬: {torch.version.cuda}")
        print(f"GPUå†…å­˜: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB")
    else:
        print("è­¦å‘Š: CUDAä¸å¯ç”¨ï¼Œå°†ä½¿ç”¨CPUè¿è¡Œ")
    
    # 1. åŸºæœ¬ä½¿ç”¨ç¤ºä¾‹
    print("\n" + "=" * 40)
    print("1. åŸºæœ¬ä½¿ç”¨ç¤ºä¾‹")
    print("=" * 40)
    example_basic_usage()
    
    # 2. CUDA kernelè¯¦ç»†æµ‹è¯•
    print("\n" + "=" * 40)
    print("2. CUDA Kernelè¯¦ç»†æµ‹è¯•")
    print("=" * 40)
    run_comprehensive_kernel_tests()
    
    # 3. æ€§èƒ½åŸºå‡†æµ‹è¯•
    print("\n" + "=" * 40)
    print("3. æ€§èƒ½åŸºå‡†æµ‹è¯•")
    print("=" * 40)
    run_performance_benchmark()
    
    # 4. ç²¾åº¦éªŒè¯æµ‹è¯•
    print("\n" + "=" * 40)
    print("4. ç²¾åº¦éªŒè¯æµ‹è¯•")
    print("=" * 40)
    run_accuracy_validation()
    
    print("\n" + "=" * 80)
    print("ğŸ‰ æ‰€æœ‰æµ‹è¯•å®Œæˆ! ğŸ‰")
    print("=" * 80)


def main():
    """ä¸»å‡½æ•° - æä¾›å¤šç§æµ‹è¯•é€‰é¡¹"""
    import argparse
    
    parser = argparse.ArgumentParser(description='HoMEä¼˜åŒ–æ¶æ„æµ‹è¯•å·¥å…·')
    parser.add_argument('--test', choices=['all', 'kernels', 'performance', 'accuracy', 'basic'], 
                       default='all', help='é€‰æ‹©è¦è¿è¡Œçš„æµ‹è¯•ç±»å‹')
    parser.add_argument('--quick', action='store_true', help='è¿è¡Œå¿«é€Ÿæµ‹è¯•ï¼ˆè·³è¿‡è¯¦ç»†åˆ†æï¼‰')
    
    args = parser.parse_args()
    
    print("HoMEä¼˜åŒ–æ¶æ„æµ‹è¯•å·¥å…·")
    print("=" * 60)
    
    # æ£€æŸ¥CUDAå¯ç”¨æ€§
    if torch.cuda.is_available():
        print(f"CUDAå¯ç”¨: {torch.cuda.get_device_name(0)}")
        print(f"CUDAç‰ˆæœ¬: {torch.version.cuda}")
    else:
        print("è­¦å‘Š: CUDAä¸å¯ç”¨ï¼Œå°†ä½¿ç”¨CPUè¿è¡Œ")
    
    if args.test == 'all':
        run_all_tests()
    elif args.test == 'kernels':
        run_comprehensive_kernel_tests()
    elif args.test == 'performance':
        run_performance_benchmark()
    elif args.test == 'accuracy':
        run_accuracy_validation()
    elif args.test == 'basic':
        example_basic_usage()
    
    if args.quick:
        print("\nâš¡ å¿«é€Ÿæµ‹è¯•æ¨¡å¼å®Œæˆ!")
    else:
        print("\nâœ… å®Œæ•´æµ‹è¯•å®Œæˆ!")


if __name__ == "__main__":
    main()
